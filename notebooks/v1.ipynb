{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e54b44e8",
   "metadata": {},
   "source": [
    "# CLM (Causal Language Modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39d048",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f463b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.8\n",
      "IPython version      : 8.9.0\n",
      "\n",
      "torch       : 2.0.0\n",
      "datasets    : 2.9.0\n",
      "transformers: 4.26.0\n",
      "wandb       : 0.14.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from datasets import DatasetDict, concatenate_datasets, load_dataset\n",
    "from tqdm import tqdm\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING, \n",
    "    AutoConfig, \n",
    "    AutoModelForCausalLM,\n",
    "    GPT2TokenizerFast, \n",
    "    HfArgumentParser, \n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -p torch,datasets,transformers,wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d1588",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15caf6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    ta_tokenizer_ckpt = '../ckpts/tamil/tokenizer'\n",
    "    ta_clm_ckpt = '../ckpts/tamil/clm'\n",
    "    en_tokenizer_ckpt = '../ckpts/english/tokenizer'\n",
    "    en_clm_ckpt = '../ckpts/english/clm'\n",
    "    context_length = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a52b8",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe305626",
   "metadata": {},
   "source": [
    "## Process Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ceabce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               text\n",
      "0   0  சிங்கமும் கழுதைப்புலியும் பசுவைப் பிடித்து வைத...\n",
      "1   1  குட்டி கழுதைப்புலி சொல்லியது: “நான் சின்னப்பயல...\n",
      "2   2  அதைக்கேட்டு கோபமான கழுதைப்புலி அந்தக் குடலோடு ...\n",
      "3   3  பசுவில் பாதி கேட்க வந்த கழுதைப்புலி தற்போது தன...\n",
      "4   4  குடலை சிங்கத்திடம் கொடுத்து விட்டு திரும்பிய க...\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "txt_files = glob('../data/tamil/*.txt')\n",
    "output_txt = '../data/ta_valid.txt'\n",
    "output_csv = '../data/ta_valid.csv'\n",
    "\n",
    "for file in txt_files:\n",
    "    with open(file, 'r') as f:\n",
    "        txt = f.read()\n",
    "        with open(output_txt, 'a') as out:\n",
    "            out.write(txt + \"\\n\")\n",
    "\n",
    "text = []\n",
    "# id = []\n",
    "for file in txt_files:\n",
    "    with open(file, 'r') as f:\n",
    "        txt = f.readlines()\n",
    "        text.extend(txt)\n",
    "        # id.extend(list(range(len(id), len(txt))))\n",
    "df = pd.DataFrame({\n",
    "    'id': range(len(text)),\n",
    "    'text': text\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78ac2fc",
   "metadata": {},
   "source": [
    "# Train Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32732c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset oscar (/Users/aneeshaparajit/.cache/huggingface/datasets/oscar/unshuffled_deduplicated_ta/1.0.0/84838bd49d2295f62008383b05620571535451d84545037bb94d6f3501651df2)\n",
      "Using custom data configuration default-4395bba7710a9245\n",
      "Found cached dataset text (/Users/aneeshaparajit/.cache/huggingface/datasets/text/default-4395bba7710a9245/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aab38b0f4254080ae2ba3fa025c6fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'id'],\n",
       "    num_rows: 32376070\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracted from https://github.com/AbinayaM02/GPT2-Tamil/blob/main/src/train_tokenizer.py\n",
    "dataset = load_dataset('oscar', 'unshuffled_deduplicated_ta', split=\"train\")\n",
    "indic_tamil = load_dataset(\n",
    "    \"text\", data_files=\"../data/data/ta/ta.txt\")['train']\n",
    "dataset = concatenate_datasets([indic_tamil, dataset])\n",
    "\n",
    "\n",
    "def batch_iterator(batch_size: int = 512):\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        yield dataset[i: i+batch_size]['text']\n",
    "\n",
    "\n",
    "def train_tokenizer():\n",
    "    tokenizer = ByteLevelBPETokenizer()\n",
    "    tokenizer.train_from_iterator(\n",
    "        batch_iterator(),\n",
    "        vocab_size=52_000,\n",
    "        min_frequency=2,\n",
    "        special_tokens=[\n",
    "            \"<s>\",\n",
    "            \"<pad>\",\n",
    "            \"</s>\",\n",
    "            \"<unk>\",\n",
    "            \"<mask>\"\n",
    "        ],\n",
    "    )\n",
    "    tokenizer.save(f\"{CFG.ta_tokenizer_ckpt}/\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "428e77d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['2019ல் 5.9 பில்லியன் அமெரிக்க டொலர் கடனை இலங்கை மீள் செலுத்த வேண்டியுள்ளதாக மத்திய வங்கியின் ஆளுநரான பேராசிரியர், இந்திரஜித் குமாரசுவாமி தெரிவித்துள்ளார்.',\n",
       "  'இப்படி தினமும் செய்தாலும், உதடுகளில் உள்ள கருமை அகலும்.'],\n",
       " 'id': [None, None]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a7542",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b5b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset oscar (/Users/aneeshaparajit/.cache/huggingface/datasets/oscar/unshuffled_deduplicated_ta/1.0.0/84838bd49d2295f62008383b05620571535451d84545037bb94d6f3501651df2)\n",
      "Using custom data configuration default-fc64922f48343321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /Users/aneeshaparajit/.cache/huggingface/datasets/csv/default-fc64922f48343321/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e79a60e3e0a4c748dc103ca77f3aa4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d516539f71e4cf1a46bb163dd01fb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /Users/aneeshaparajit/.cache/huggingface/datasets/csv/default-fc64922f48343321/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112673d81df74be7a3aea04d4c2223e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text'],\n",
       "        num_rows: 833101\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['id', 'text'],\n",
       "        num_rows: 1740\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_datasets():\n",
    "    ds_train = load_dataset('oscar', 'unshuffled_deduplicated_ta', split=\"train\")\n",
    "    ds_valid = load_dataset(\"csv\", data_files=\"../data/ta_valid.csv\")['train']\n",
    "    raw_ds = DatasetDict({\n",
    "        'train': ds_train, \n",
    "        'valid': ds_valid\n",
    "    })\n",
    "    return raw_ds\n",
    "\n",
    "raw_dataset = get_datasets()\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be87d37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='', vocab_size=52000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast(tokenizer_file='../ckpts/tamil/tokenizer/tokenizer.json')\n",
    "tokenizer.add_special_tokens({\n",
    "    'bos_token': '<s>',\n",
    "    'eos_token': '</s>',\n",
    "    'unk_token': '<unk>',\n",
    "    'pad_token': '<pad>'\n",
    "})\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa07dffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = raw_dataset['train'][:5]['text']\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0985d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tokenizer(\n",
    "    text=text, \n",
    "    truncation=True, \n",
    "    max_length=CFG.context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    padding=True,\n",
    "    return_length=True, \n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8897f8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([260, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c46d87b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'length', 'overflow_to_sample_mapping'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fec6e91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]),\n",
      " 'input_ids': tensor([[285, 318, 320,  ..., 203, 269, 265],\n",
      "        [277, 267, 299,  ..., 307, 265, 277],\n",
      "        [286, 271, 262,  ..., 262, 269, 267],\n",
      "        ...,\n",
      "        [302, 306, 262,  ..., 267, 556, 367],\n",
      "        [309, 267, 301,  ..., 294, 275, 292],\n",
      "        [275, 279, 421,  ...,   1,   1,   1]]),\n",
      " 'length': tensor([128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128]),\n",
      " 'overflow_to_sample_mapping': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])}\n"
     ]
    }
   ],
   "source": [
    "__import__('pprint').pprint(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01dd46d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88068dbd727446e9f8c4436b1d6950b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/834 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a45d7a5ba2143cdbf75491b08efd853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 11943163\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 2657\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(item):\n",
    "    outputs = tokenizer(\n",
    "        text=item['text'], \n",
    "        truncation=True, \n",
    "        max_length=CFG.context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        padding=True,\n",
    "        return_length=True, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == CFG.context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "tokenized_datasets = raw_dataset.map(\n",
    "    tokenize, batched=True, remove_columns=raw_dataset[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edbc3d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8da052a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('<s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4524ad2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f35e7dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f545a75f54894eb8a6e0b6e7d24305d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/876 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    \"abinayam/gpt-2-tamil\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=CFG.context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d491b2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 125.8M parameters\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_config(config)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b17c0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "480fb226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([5, 128])\n",
      "attention_mask shape: torch.Size([5, 128])\n",
      "labels shape: torch.Size([5, 128])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([tokenized_datasets[\"train\"][i] for i in range(5)])\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75b5550d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_14065/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2351947026.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_14065/2351947026.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;string&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">108</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">training_args.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1176</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__post_init__</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1173 │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (get_xla_device_type(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device) != <span style=\"color: #808000; text-decoration-color: #808000\">\"GPU\"</span>)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1174 │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fp16 <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fp16_full_eval)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1175 │   │   </span>):                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1176 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1177 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1178 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" (`--fp16_full_eval`) can only be used on CUDA devices.\"</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1179 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>FP16 Mixed precision training with AMP or APEX <span style=\"font-weight: bold\">(</span>`--fp16`<span style=\"font-weight: bold\">)</span> and FP16 half precision evaluation \n",
       "<span style=\"font-weight: bold\">(</span>`--fp16_full_eval`<span style=\"font-weight: bold\">)</span> can only be used on CUDA devices.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_14065/\u001b[0m\u001b[1;33m2351947026.py\u001b[0m:\u001b[94m3\u001b[0m in \u001b[92m<module>\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_14065/2351947026.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<string>\u001b[0m:\u001b[94m108\u001b[0m in \u001b[92m__init__\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1176\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__post_init__\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1173 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (get_xla_device_type(\u001b[96mself\u001b[0m.device) != \u001b[33m\"\u001b[0m\u001b[33mGPU\u001b[0m\u001b[33m\"\u001b[0m)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1174 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.fp16 \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.fp16_full_eval)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1175 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1176 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1177 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1178 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m (`--fp16_full_eval`) can only be used on CUDA devices.\u001b[0m\u001b[33m\"\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1179 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mFP16 Mixed precision training with AMP or APEX \u001b[1m(\u001b[0m`--fp16`\u001b[1m)\u001b[0m and FP16 half precision evaluation \n",
       "\u001b[1m(\u001b[0m`--fp16_full_eval`\u001b[1m)\u001b[0m can only be used on CUDA devices.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"codeparrot-ds\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5_000,\n",
    "    logging_steps=5_000,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
